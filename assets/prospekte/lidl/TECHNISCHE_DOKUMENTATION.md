# ğŸ”§ Technische Dokumentation - LIDL PDF Extraktion

## ğŸ“‹ Ãœbersicht

Das Script `extract_lidl_offers_vision.py` extrahiert Lebensmittel-Angebote aus einer LIDL-PDF mithilfe von **GPT-4o Vision** (Multimodal LLM). Der Prozess nutzt Bildverarbeitung und KI-Analyse fÃ¼r maximale Genauigkeit.

---

## ğŸ”„ Workflow (Step-by-Step)

### 1. **Initialisierung & Setup**

```
Script startet
  â†“
LÃ¤dt OPENAI_API_KEY (.env oder Environment-Variable)
  â†“
Findet PDF-Datei im Script-Ordner (grÃ¶ÃŸte .pdf Datei)
  â†“
Initialisiert OpenAI Client
```

**Code:**
- `.env` Loading mit mehreren Pfad-Versuchen
- Automatische PDF-Suche via `Path.glob("*.pdf")`
- Fehlerbehandlung bei fehlendem API-Key

---

### 2. **PDF â†’ Bilder Konvertierung**

```
PDF-Datei (57 Seiten, 45.5 MB)
  â†“
pdf2image.convert_from_path()
  â†“
57 PNG-Bilder (300 DPI, RGB)
```

**Technik:**
- **Bibliothek:** `pdf2image` (nutzt `poppler` unter der Haube)
- **AuflÃ¶sung:** 300 DPI (hoch genug fÃ¼r OCR, nicht zu groÃŸ fÃ¼r API)
- **Format:** PNG (RGB), jedes Bild = eine PDF-Seite

**Warum Bilder?**
- PDFs sind oft nicht direkt text-extrahierbar (Layout-basiert, eingebettete Bilder)
- GPT Vision kann visuelle Layouts besser verstehen
- Funktioniert auch bei gescannten/sehr grafischen PDFs

---

### 3. **Tile-basierte Bildaufteilung**

```
1 Seite (z.B. 1654Ã—2339 Pixel)
  â†“
split_image_into_tiles() - 2Ã—3 Grid
  â†“
6 Kacheln (ca. 827Ã—780 Pixel pro Kachel)
```

**Code-Logik:**
```python
def split_image_into_tiles(image, grid_size=(2, 3)):
    width, height = image.size
    tile_width = width // grid_size[0]   # 827 Pixel
    tile_height = height // grid_size[1]  # 780 Pixel
    
    for row in range(grid_size[1]):
        for col in range(grid_size[0]):
            left = col * tile_width
            top = row * tile_height
            right = left + tile_width
            bottom = top + tile_height
            
            tile = image.crop((left, right, top, bottom))
            tiles.append(tile)
```

**Warum Kacheln?**
- **Token-Limit:** GPT Vision hat Limits fÃ¼r BildgrÃ¶ÃŸe/Token
- **Fokus:** Kleinere Kacheln = bessere Erkennung von Details
- **ParallelitÃ¤t:** Theoretisch parallelisierbar (aktuell sequenziell)
- **Genauigkeit:** Vermeidet Ãœbersehen von kleinen Angeboten

**Grid-GrÃ¶ÃŸe:** 2Ã—3 = **6 Kacheln pro Seite**
- Pro 57 Seiten = **342 API-Calls**

---

### 4. **Base64-Encoding fÃ¼r API**

```
PNG-Kachel (ca. 827Ã—780 Pixel)
  â†“
PIL.Image â†’ Bytes
  â†“
base64.b64encode()
  â†“
Base64-String (z.B. "iVBORw0KGgoAAAANSUhEUgAA...")
```

**Format fÃ¼r OpenAI API:**
```json
{
  "type": "image_url",
  "image_url": {
    "url": "data:image/png;base64,{base64_string}"
  }
}
```

**Warum Base64?**
- OpenAI API erwartet Base64-encoded Bilder
- `data:` URL-Schema fÃ¼r Inline-Bilder
- Keine externe Bild-URL nÃ¶tig

---

### 5. **GPT-4o Vision API Call**

```
Kachel-Base64 + Prompt
  â†“
OpenAI Chat Completions API (model: "gpt-4o")
  â†“
JSON-Response mit extrahierten Angeboten
```

**API Request:**
```python
response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{
        "role": "user",
        "content": [
            {"type": "text", "text": EXTRACTION_PROMPT},
            {"type": "image_url", "image_url": {"url": f"data:image/png;base64,{base64}"}}
        ]
    }],
    max_tokens=4000,
    temperature=0.1  # Niedrig fÃ¼r konsistente Extraktion
)
```

**Prompt-Strategie:**
- **Detailliertes Schema:** Alle gewÃ¼nschten Felder explizit definiert
- **Klare Regeln:** Nur Lebensmittel, keine Haushaltswaren
- **Format-Anforderung:** "Return ONLY a JSON array. No markdown."
- **VollstÃ¤ndigkeit:** "Extrahiere ALLE Angebote! Kein einziges darf Ã¼bersehen werden!"

**Temperature 0.1:**
- Niedrige VariabilitÃ¤t = konsistente Extraktion
- Wichtig fÃ¼r strukturierte Daten-Extraktion

---

### 6. **JSON-Parsing & Normalisierung**

```
GPT Response (manchmal mit Markdown-Fences)
  â†“
Entferne "```json" und "```"
  â†“
json.loads() â†’ Python Dict/List
  â†“
Normalisiere zu internem Schema
  â†“
Validiere (product_name + price vorhanden)
```

**Robuste Parsing-Strategie:**
```python
# 1. Entferne Markdown-Fences
if "```json" in content:
    start = content.find("```json") + 7
    end = content.find("```", start)
    content = content[start:end].strip()

# 2. Finde JSON-Array (falls Text davor/danach)
start_idx = content.find('[')
# ... Finde passende ']' ...

# 3. Parse JSON
offers_raw = json.loads(content)
```

**Normalisierung:**
- GPT-Output: `exact_name`, `price_eur`, `unit`, etc.
- Internes Format: `product_name`, `offer_price`, `quantity`, etc.
- Mapping zwischen beiden Formaten

**Validierung:**
- Nur Angebote mit `product_name` UND `offer_price > 0`
- Filtert leere/ungÃ¼ltige EintrÃ¤ge

---

### 7. **Deduplizierung (pro Seite & global)**

**Pro Seite (innerhalb von `extract_offers_from_image`):**
```
6 Kacheln â†’ Alle Angebote
  â†“
Vergleiche: (product_name.lower()[:50], price)
  â†“
Entferne Duplikate (gleiche Seite kann Ã¼berlappende Kacheln haben)
```

**Global (nach allen Seiten):**
```
Alle Seiten â†’ Alle Angebote
  â†“
deduplicate_offers() - Vergleich (product_name[:50], price)
  â†“
Eindeutige Angebote
```

**Deduplizierungs-Key:**
```python
product_name = offer["product_name"].lower().strip()[:50]  # Erste 50 Zeichen
price = round(float(offer["offer_price"]), 2)  # 2 Dezimalstellen
key = (product_name, price)
```

**Warum 50 Zeichen?**
- Vermeidet Duplikate durch leichte Namensvariationen
- Ausreichend fÃ¼r eindeutige Identifikation

---

### 8. **Fehlerbehandlung & Retries**

**JSON-Parse-Fehler:**
- 3 Retries mit exponential backoff (1s, 2s, 3s)
- Bei weiterem Fehler: Ãœberspringe Kachel (leere Liste zurÃ¼ck)

**Rate Limit (429 Error):**
- 5 Retries mit exponential backoff (4s, 8s, 16s, 32s, 64s)
- LÃ¤ngere Wartezeiten, da API-Limit

**API-Key-Fehler (401/403):**
- Sofortiger Exit (kritischer Fehler)

**Andere Fehler:**
- 2 Retries
- Bei weiterem Fehler: Ãœberspringe Kachel (Script lÃ¤uft weiter)

---

### 9. **Output-Generierung**

**Text-Datei (`lidl.txt`):**
```
LIDL ANGEBOTE
============================================================
Quelle: kaufDA - Lidl - LIDL LOHNT SICH.pdf
Anzahl Angebote: 234
============================================================

1. Produktname ğŸ“± LIDL PLUS
   Angebotspreis: 1.99 â‚¬
   Statt: 2.49 â‚¬
   Menge: 500 g
   ...
```

**JSON-Datei (`lidl.json`):**
```json
[
  {
    "product_name": "Produktname",
    "offer_price": 1.99,
    "quantity": "500 g",
    "lidl_plus": true,
    "lidl_plus_only": false,
    "brand": "Markenname",
    "category": "Kategorie",
    "page": 2,
    ...
  },
  ...
]
```

---

## ğŸ“Š Datenfluss-Diagramm

```
PDF (45.5 MB, 57 Seiten)
    â”‚
    â”œâ”€â†’ [PDF â†’ PNG] (pdf2image, 300 DPI)
    â”‚       â”‚
    â”‚       â”œâ”€â†’ Seite 1 (1654Ã—2339 px)
    â”‚       â”‚       â”‚
    â”‚       â”‚       â”œâ”€â†’ [Tile 1] â†’ Base64 â†’ GPT Vision â†’ JSON â†’ Angebote
    â”‚       â”‚       â”œâ”€â†’ [Tile 2] â†’ Base64 â†’ GPT Vision â†’ JSON â†’ Angebote
    â”‚       â”‚       â”œâ”€â†’ [Tile 3] â†’ Base64 â†’ GPT Vision â†’ JSON â†’ Angebote
    â”‚       â”‚       â”œâ”€â†’ [Tile 4] â†’ Base64 â†’ GPT Vision â†’ JSON â†’ Angebote
    â”‚       â”‚       â”œâ”€â†’ [Tile 5] â†’ Base64 â†’ GPT Vision â†’ JSON â†’ Angebote
    â”‚       â”‚       â””â”€â†’ [Tile 6] â†’ Base64 â†’ GPT Vision â†’ JSON â†’ Angebote
    â”‚       â”‚
    â”‚       â”œâ”€â†’ Seite 2 â†’ ... (gleich)
    â”‚       â””â”€â†’ ... (57 Seiten)
    â”‚
    â”œâ”€â†’ [Deduplizierung] (pro Seite + global)
    â”‚
    â””â”€â†’ [Output]
            â”œâ”€â†’ lidl.txt (human-readable)
            â””â”€â†’ lidl.json (machine-readable)
```

---

## âš™ï¸ Technische Details

### **AbhÃ¤ngigkeiten:**

```python
openai>=1.0.0          # OpenAI API Client
pdf2image>=1.16.0      # PDF â†’ PNG Konvertierung
Pillow>=10.0.0         # Bildverarbeitung (crop, encode)
python-dotenv>=1.0.0   # .env Datei Loading
```

**System-AbhÃ¤ngigkeiten:**
- `poppler` (fÃ¼r pdf2image) - Install via: `brew install poppler`

---

### **Rate Limiting:**

- **Pause zwischen Kacheln:** 0.3s
- **Pause zwischen Seiten:** 0.5s
- **Retry bei Rate Limit:** Exponential backoff (4s â†’ 64s)

**Warum?**
- OpenAI API hat Rate Limits (Requests pro Minute)
- Pausen vermeiden 429 Errors
- Exponential backoff bei Limit-Erreichen

---

### **Token-Usage:**

- **Pro Bild-Kachel:** ~800-1200 Input-Tokens (Bild + Prompt)
- **Output:** ~100-500 Tokens pro Kachel (je nach Anzahl Angebote)
- **Total:** ~342 API-Calls Ã— ~1500 Tokens = **~513.000 Tokens**

**Kosten-SchÃ¤tzung (GPT-4o):**
- Input: ~342 Ã— 1200 Ã— $0.0025/1K = **~$1.03**
- Output: ~342 Ã— 300 Ã— $0.01/1K = **~$1.03**
- **Total: ~$2.06 pro Lauf** (fÃ¼r 57 Seiten)

---

## ğŸ¯ Warum diese Methode?

### **Vorteile:**

1. âœ… **Hohe Genauigkeit** - GPT Vision erkennt Layout, Preise, Badges
2. âœ… **Robust** - Funktioniert auch bei grafischen/sehr komplexen PDFs
3. âœ… **VollstÃ¤ndig** - Extrahiert ALLE Felder (LIDL Plus, Marken, etc.)
4. âœ… **Kein OCR nÃ¶tig** - GPT Vision "versteht" das Bild direkt
5. âœ… **BewÃ¤hrt** - "lief perfekt durch" (User-Feedback)

### **Nachteile:**

1. âš ï¸ **Langsam** - ~10-20 Minuten fÃ¼r 57 Seiten
2. âš ï¸ **Kosten** - ~$2 pro Lauf
3. âš ï¸ **API-AbhÃ¤ngig** - BenÃ¶tigt Internet + OpenAI API Key

### **Alternativen (verworfen):**

- **PDF-to-Text:** Lief bei dieser PDF schlecht (hauptsÃ¤chlich URLs)
- **Playwright/Web-Scraping:** Extrahiert oft Non-Food-Items, benÃ¶tigt aktive URL
- **OCR (Tesseract):** UnprÃ¤zise, erfordert Post-Processing

---

## ğŸ” Debugging & Monitoring

**Fortschrittsanzeige:**
```
[12/57] Seite 12...       â†’ 6 Kacheln (Grid: 2x3)
         Kachel 2: 1 Angebote
         Kachel 5: 3 Angebote
âœ“ 4 Angebote
```

**Fehler-Indikatoren:**
- `âš ï¸ JSON-Parse-Fehler` - GPT gab kein gÃ¼ltiges JSON zurÃ¼ck
- `âš ï¸ Keine Angebote` - Keine Lebensmittel in dieser Kachel
- `â³ Rate Limit - warte Xs...` - API-Limit erreicht, wartet

**Ergebnis-Ãœbersicht:**
```
ğŸ”„ Deduplizierung (342 â†’ 234 eindeutige Angebote)
ğŸ’¾ Speichere lidl.txt...
ğŸ’¾ Speichere lidl.json...
âœ… Fertig! 234 Angebote extrahiert
```

---

## ğŸ“ Zusammenfassung

Das Script nutzt **GPT-4o Vision** fÃ¼r die Extraktion, kombiniert mit **tile-basierter Bildaufteilung** fÃ¼r maximale Genauigkeit. Der Prozess ist robust gegenÃ¼ber Fehlern (Retries, Rate Limits) und extrahiert strukturierte Daten direkt aus dem visuellen Layout der PDF-Seiten.

**Kern-Idee:** PDF â†’ Bilder â†’ Kacheln â†’ GPT Vision â†’ JSON â†’ Strukturierte Daten
