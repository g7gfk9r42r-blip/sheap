# Prospekt Pipeline - Ultra-Robust Supermarket Flyer Parser

A fully self-healing, modular parsing pipeline for supermarket prospekt (flyer) extraction. This system **always** produces valid `offers.json` files, even when input data is incomplete, broken, or messy.

## ğŸ¯ Core Philosophy

**Error tolerance is priority #1.** The system never crashes and always produces output, even if it's an empty offers list with detailed error metadata.

## ğŸ“ Architecture

```
prospekt_pipeline/
â”œâ”€â”€ parsers/           # Extraction modules
â”‚   â”œâ”€â”€ html_parser.py      # BeautifulSoup-based HTML parsing (confidence: 0.85-1.0)
â”‚   â”œâ”€â”€ pdf_parser.py       # pdfminer text extraction (confidence: 0.50-0.80)
â”‚   â”œâ”€â”€ ocr_parser.py       # pytesseract OCR fallback (confidence: 0.20-0.50)
â”‚   â””â”€â”€ fallback_parser.py  # Last-resort heuristics (confidence: 0.0-0.25)
â”œâ”€â”€ pipeline/         # Orchestration
â”‚   â”œâ”€â”€ process_prospekt.py  # Main processor (never crashes)
â”‚   â”œâ”€â”€ merge_results.py     # Deduplication & merging
â”‚   â”œâ”€â”€ normalize.py         # Data normalization
â”‚   â””â”€â”€ validate.py  # Input validation
â”œâ”€â”€ utils/            # Shared utilities
â”‚   â”œâ”€â”€ logger.py           # Custom logging with FALLBACK level
â”‚   â”œâ”€â”€ exceptions.py        # Exception hierarchy
â”‚   â”œâ”€â”€ file_loader.py      # Safe file I/O
â”‚   â”œâ”€â”€ ocr_cleaner.py      # OCR text cleaning
â”‚   â””â”€â”€ brand_heuristics.json # Brand recognition rules
â”œâ”€â”€ cli/              # Command-line interface
â”‚   â””â”€â”€ run_parser.py        # Main entry point
â””â”€â”€ tests/            # Comprehensive test suite
    â”œâ”€â”€ test_html_parser.py
    â”œâ”€â”€ test_pdf_parser.py
    â”œâ”€â”€ test_ocr_parser.py
    â”œâ”€â”€ test_fallback_parser.py
    â”œâ”€â”€ test_merge.py
    â”œâ”€â”€ test_normalize.py
    â”œâ”€â”€ test_process_integration.py
    â””â”€â”€ test_confidence_scores.py
```

## ğŸš€ Quick Start

### Installation

```bash
pip install beautifulsoup4 pdfminer.six pdf2image pillow pytesseract
```

### Usage

```bash
# Process all prospekt folders recursively
python -m prospekt_pipeline.cli.run_parser --base media/prospekte

# Process a single folder
python -m prospekt_pipeline.cli.run_parser --folder media/prospekte/edeka/berlin

# With custom log level
python -m prospekt_pipeline.cli.run_parser --base media/prospekte --log-level DEBUG
```

### Expected Folder Structure

```
media/prospekte/
â”œâ”€â”€ edeka/
â”‚   â”œâ”€â”€ berlin/
â”‚   â”‚   â”œâ”€â”€ raw.html
â”‚   â”‚   â”œâ”€â”€ raw.pdf
â”‚   â”‚   â””â”€â”€ offers.json  (generated)
â”‚   â””â”€â”€ mÃ¼nchen/
â”‚       â”œâ”€â”€ raw.html
â”‚       â”œâ”€â”€ raw.pdf
â”‚       â””â”€â”€ offers.json  (generated)
â””â”€â”€ lidl/
    â””â”€â”€ ...
```

## ğŸ”„ Processing Pipeline

1. **Validate Sources** - Check HTML/PDF availability and quality
2. **HTML Parsing** - Primary extraction (highest confidence)
3. **PDF Parsing** - Fallback if HTML missing/incomplete
4. **OCR Parsing** - If PDF text extraction fails
5. **Fallback Parsing** - Last-resort text scavenging
6. **Merge Results** - Deduplicate and combine all sources
7. **Normalize** - Clean and standardize data
8. **Write JSON** - Always produces valid output

## ğŸ“Š Output Format

```json
{
  "metadata": {
    "folder": "media/prospekte/edeka/berlin",
    "html_candidates": 45,
    "pdf_candidates": 42,
    "ocr_candidates": 8,
    "fallback_candidates": 0,
    "final_offers": 38
  },
  "offers": [
    {
      "title": "test kaffee",
      "price": 4.99,
      "unit_price": 9.98,
      "confidence": 0.95,
      "source": "html"
    }
  ]
}
```

## ğŸ›¡ï¸ Error Handling

- **HTML parsing fails** â†’ Falls back to PDF
- **PDF parsing fails** â†’ Falls back to OCR
- **OCR fails** â†’ Falls back to text scavenging
- **All parsers fail** â†’ Writes empty `offers.json` with error metadata
- **File I/O errors** â†’ Logged, processing continues
- **Invalid data** â†’ Normalized to safe defaults

## ğŸ§ª Testing

```bash
# Run all tests
pytest prospekt_pipeline/tests/

# Run specific test
pytest prospekt_pipeline/tests/test_html_parser.py

# With coverage
pytest prospekt_pipeline/tests/ --cov=prospekt_pipeline
```

## ğŸ“ Confidence Scores

- **HTML Parser**: 0.85-1.0 (structured data, highest reliability)
- **PDF Parser**: 0.50-0.80 (text extraction, medium reliability)
- **OCR Parser**: 0.20-0.50 (image recognition, lower reliability)
- **Fallback Parser**: 0.0-0.25 (heuristic matching, lowest reliability)

## ğŸ”§ Configuration

### Brand Heuristics

Edit `utils/brand_heuristics.json` to add known brands and weak suffixes:

```json
{
  "brands": ["coca cola", "milka", "lindt"],
  "weak_suffixes": ["original", "classic", "medium"]
}
```

### Logging

The logger supports custom `FALLBACK` level (25) for fallback operations:

```python
from prospekt_pipeline.utils.logger import get_logger
logger = get_logger("my_module")
logger.fallback("Using fallback parser")
```

## ğŸ“ Key Features

- âœ… **Never crashes** - All exceptions caught and logged
- âœ… **Always produces JSON** - Even if empty
- âœ… **Self-healing** - Automatically tries fallbacks
- âœ… **Deduplication** - Fuzzy matching prevents duplicates
- âœ… **Confidence scoring** - Tracks data quality
- âœ… **Comprehensive logging** - INFO, WARNING, FALLBACK, ERROR
- âœ… **Type-annotated** - Full type hints for Python 3.11+
- âœ… **Tested** - Comprehensive test suite

## ğŸ“š Module Documentation

### Parsers

- **html_parser.py**: Extracts structured data from HTML using BeautifulSoup
- **pdf_parser.py**: Extracts text from PDF using pdfminer
- **ocr_parser.py**: OCR fallback using pytesseract with preprocessing
- **fallback_parser.py**: Last-resort text pattern matching

### Pipeline

- **process_prospekt.py**: Main orchestrator (never crashes)
- **merge_results.py**: Deduplicates and merges parser outputs
- **normalize.py**: Cleans and standardizes offer data
- **validate.py**: Validates input files before processing

### Utils

- **logger.py**: Custom logging with FALLBACK level
- **exceptions.py**: Exception hierarchy
- **file_loader.py**: Safe file I/O operations
- **ocr_cleaner.py**: OCR text cleaning utilities

## ğŸ› Troubleshooting

### No offers extracted

- Check logs for parser errors
- Verify HTML/PDF files are valid
- Try increasing OCR preprocessing quality
- Check brand_heuristics.json configuration

### Low confidence scores

- HTML parser preferred over PDF/OCR
- Missing prices reduce confidence
- Unit prices increase confidence
- Fallback parser has lowest confidence

### Processing slow

- OCR is the slowest step (only runs when needed)
- PDF parsing is faster than OCR
- HTML parsing is fastest
- Consider processing folders in parallel

## ğŸ“„ License

Internal project - All rights reserved.

