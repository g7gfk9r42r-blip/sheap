# Prospekt Pipeline - Selbstheilende Supermarkt-Prospekt-Parser

Eine vollstÃ¤ndig selbstheilende, modulare Parsing-Pipeline fÃ¼r Supermarkt-Prospekte (Flyer). Dieses System **produziert immer** gÃ¼ltige `offers.json` Dateien, auch wenn die Eingabedaten unvollstÃ¤ndig, defekt oder chaotisch sind.

## ğŸ¯ Kernphilosophie

**Fehlertoleranz ist PrioritÃ¤t #1.** Das System stÃ¼rzt niemals ab und produziert immer Output, auch wenn es nur eine leere Angebotsliste mit detaillierten Fehlermetadaten ist.

## ğŸ“ Architektur

```
prospekt_pipeline/
â”œâ”€â”€ parsers/              # Extraktions-Module
â”‚   â”œâ”€â”€ html_parser.py        # BeautifulSoup-basiertes HTML-Parsing (confidence: 1.0)
â”‚   â”œâ”€â”€ pdf_parser.py         # pdfminer Text-Extraktion (confidence: 0.7)
â”‚   â”œâ”€â”€ ocr_parser.py         # pytesseract OCR-Fallback (confidence: 0.5)
â”‚   â””â”€â”€ fallback_parser.py    # Letzte Heuristik (confidence: 0.3)
â”œâ”€â”€ pipeline/            # Orchestrierung
â”‚   â”œâ”€â”€ process_prospekt.py   # Hauptprozessor (stÃ¼rzt nie ab)
â”‚   â”œâ”€â”€ merge_results.py      # Deduplizierung & Merging
â”‚   â”œâ”€â”€ normalize.py          # Daten-Normalisierung
â”‚   â””â”€â”€ validate.py           # Input-Validierung
â”œâ”€â”€ utils/               # Gemeinsame Utilities
â”‚   â”œâ”€â”€ logger.py             # Custom Logging mit FALLBACK-Level
â”‚   â”œâ”€â”€ exceptions.py         # Exception-Hierarchie
â”‚   â”œâ”€â”€ file_loader.py        # Sichere Datei-I/O
â”‚   â”œâ”€â”€ ocr_cleaner.py        # OCR-Text-Bereinigung
â”‚   â””â”€â”€ brand_heuristics.json # Markenerkennungs-Regeln
â”œâ”€â”€ cli/                 # Command-Line Interface
â”‚   â””â”€â”€ run_parser.py         # Haupt-Einstiegspunkt
â””â”€â”€ tests/               # Umfassende Test-Suite
    â”œâ”€â”€ test_html_parser.py
    â”œâ”€â”€ test_pdf_parser.py
    â”œâ”€â”€ test_ocr_parser.py
    â”œâ”€â”€ test_fallback_parser.py
    â”œâ”€â”€ test_merge.py
    â”œâ”€â”€ test_normalize.py
    â”œâ”€â”€ test_confidence_scores.py
    â”œâ”€â”€ test_process_integration.py
    â””â”€â”€ test_sample_pipeline.py
```

## ğŸš€ Schnellstart

### Installation

```bash
# Alle Dependencies installieren
pip install -r prospekt_pipeline/requirements.txt

# FÃ¼r Tests (optional)
pip install pytest pytest-cov
```

### Verwendung

```bash
# Alle Prospekt-Ordner rekursiv verarbeiten
python3 -m prospekt_pipeline.cli.run_parser --base media/prospekte

# Einzelnen Ordner verarbeiten
python3 -m prospekt_pipeline.cli.run_parser --folder media/prospekte/edeka/berlin

# Mit custom Log-Level
python3 -m prospekt_pipeline.cli.run_parser --base media/prospekte --log-level DEBUG
```

### Erwartete Ordnerstruktur

```
media/prospekte/
â”œâ”€â”€ edeka/
â”‚   â”œâ”€â”€ berlin/
â”‚   â”‚   â”œâ”€â”€ raw.html
â”‚   â”‚   â”œâ”€â”€ raw.pdf
â”‚   â”‚   â””â”€â”€ offers.json  (generiert)
â”‚   â””â”€â”€ mÃ¼nchen/
â”‚       â”œâ”€â”€ raw.html
â”‚       â”œâ”€â”€ raw.pdf
â”‚       â””â”€â”€ offers.json  (generiert)
â””â”€â”€ lidl/
    â””â”€â”€ ...
```

## ğŸ”„ Verarbeitungs-Pipeline

1. **Quellen validieren** - PrÃ¼ft HTML/PDF VerfÃ¼gbarkeit und QualitÃ¤t
2. **HTML-Parsing** - PrimÃ¤re Extraktion (hÃ¶chste Confidence)
3. **PDF-Parsing** - Fallback wenn HTML fehlt/unvollstÃ¤ndig
4. **OCR-Parsing** - Wenn PDF-Text-Extraktion fehlschlÃ¤gt
5. **Fallback-Parsing** - Letzte Text-Scavenging-Heuristik
6. **Ergebnisse mergen** - Dedupliziert und kombiniert alle Quellen
7. **Normalisieren** - Bereinigt und standardisiert Daten
8. **JSON schreiben** - Produziert immer gÃ¼ltigen Output

## ğŸ“Š Output-Format

```json
{
  "metadata": {
    "folder": "media/prospekte/edeka/berlin",
    "html_candidates": 45,
    "pdf_candidates": 42,
    "ocr_candidates": 8,
    "fallback_candidates": 0,
    "final_offers": 38
  },
  "offers": [
    {
      "title": "test kaffee",
      "price": 4.99,
      "unit_price": 9.98,
      "confidence": 1.0,
      "source": "html"
    }
  ]
}
```

## ğŸ›¡ï¸ Fehlerbehandlung

- **HTML-Parsing schlÃ¤gt fehl** â†’ FÃ¤llt zurÃ¼ck auf PDF
- **PDF-Parsing schlÃ¤gt fehl** â†’ FÃ¤llt zurÃ¼ck auf OCR
- **OCR schlÃ¤gt fehl** â†’ FÃ¤llt zurÃ¼ck auf Text-Scavenging
- **Alle Parser schlagen fehl** â†’ Schreibt leere `offers.json` mit Fehlermetadaten
- **Datei-I/O-Fehler** â†’ Geloggt, Verarbeitung setzt fort
- **UngÃ¼ltige Daten** â†’ Normalisiert zu sicheren Standardwerten

## ğŸ§ª Testing

```bash
# Alle Tests ausfÃ¼hren
./prospekt_pipeline/run_tests.sh

# Oder direkt
python3 -m pytest prospekt_pipeline/tests/ -v

# Spezifischen Test ausfÃ¼hren
python3 -m pytest prospekt_pipeline/tests/test_html_parser.py -v
```

## ğŸ“ Confidence-Scores

- **HTML Parser**: 1.0 (strukturierte Daten, hÃ¶chste ZuverlÃ¤ssigkeit)
- **PDF Parser**: 0.7 (Text-Extraktion, mittlere ZuverlÃ¤ssigkeit)
- **OCR Parser**: 0.5 (Bilderkennung, niedrigere ZuverlÃ¤ssigkeit)
- **Fallback Parser**: 0.3 (heuristisches Matching, niedrigste ZuverlÃ¤ssigkeit)

## ğŸ”§ Konfiguration

### Brand Heuristics

Bearbeite `utils/brand_heuristics.json` um bekannte Marken und schwache Suffixe hinzuzufÃ¼gen:

```json
{
  "brands": ["coca cola", "milka", "lindt"],
  "weak_suffixes": ["original", "classic", "medium"]
}
```

### Logging

Der Logger unterstÃ¼tzt ein custom `FALLBACK`-Level (25) fÃ¼r Fallback-Operationen:

```python
from prospekt_pipeline.utils.logger import get_logger
logger = get_logger("my_module")
logger.fallback("Using fallback parser")
```

## ğŸ“ Hauptfeatures

- âœ… **StÃ¼rzt nie ab** - Alle Exceptions werden abgefangen und geloggt
- âœ… **Produziert immer JSON** - Auch wenn leer
- âœ… **Selbstheilend** - Versucht automatisch Fallbacks
- âœ… **Deduplizierung** - Fuzzy-Matching verhindert Duplikate
- âœ… **Confidence-Scoring** - Verfolgt DatenqualitÃ¤t
- âœ… **Umfassendes Logging** - INFO, WARNING, FALLBACK, ERROR
- âœ… **Type-annotated** - VollstÃ¤ndige Type-Hints fÃ¼r Python 3.11+
- âœ… **Getestet** - Umfassende Test-Suite

## ğŸ“š Modul-Dokumentation

### Parser

- **html_parser.py**: Extrahiert strukturierte Daten aus HTML mit BeautifulSoup
- **pdf_parser.py**: Extrahiert Text aus PDF mit pdfminer
- **ocr_parser.py**: OCR-Fallback mit pytesseract und Preprocessing
- **fallback_parser.py**: Letzte Text-Pattern-Matching-Heuristik

### Pipeline

- **process_prospekt.py**: Haupt-Orchestrator (stÃ¼rzt nie ab)
- **merge_results.py**: Dedupliziert und merged Parser-Outputs
- **normalize.py**: Bereinigt und standardisiert Angebotsdaten
- **validate.py**: Validiert Eingabedateien vor der Verarbeitung

### Utils

- **logger.py**: Custom Logging mit FALLBACK-Level
- **exceptions.py**: Exception-Hierarchie
- **file_loader.py**: Sichere Datei-I/O-Operationen
- **ocr_cleaner.py**: OCR-Text-Bereinigungs-Utilities

## ğŸ› Troubleshooting

### Keine Angebote extrahiert

- PrÃ¼fe Logs auf Parser-Fehler
- Verifiziere HTML/PDF-Dateien sind gÃ¼ltig
- Versuche OCR-Preprocessing-QualitÃ¤t zu erhÃ¶hen
- PrÃ¼fe brand_heuristics.json Konfiguration

### Niedrige Confidence-Scores

- HTML-Parser bevorzugt Ã¼ber PDF/OCR
- Fehlende Preise reduzieren Confidence
- Einheitspreise erhÃ¶hen Confidence
- Fallback-Parser hat niedrigste Confidence

### Langsame Verarbeitung

- OCR ist der langsamste Schritt (lÃ¤uft nur wenn nÃ¶tig)
- PDF-Parsing ist schneller als OCR
- HTML-Parsing ist am schnellsten
- ErwÃ¤ge parallele Ordner-Verarbeitung

## ğŸ“„ Lizenz

Internes Projekt - Alle Rechte vorbehalten.

